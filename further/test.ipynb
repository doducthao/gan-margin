{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler, Sampler\n",
    "import torchvision.datasets\n",
    "\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame\n",
    "import threading\n",
    "\n",
    "\n",
    "from mean_teacher import architectures, datasets, data, losses, ramps, cli\n",
    "from mean_teacher.run_context import RunContext\n",
    "from mean_teacher.data import NO_LABEL\n",
    "from mean_teacher.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):  # # #\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 4,2,1可以将大小扩大一倍\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.fc(input)\n",
    "        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n",
    "        x = self.deconv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class discriminator(nn.Module):  # # #\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, 4, 2, 1), # 4，2，1缩小1倍\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2)            \n",
    "        )\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(output_dim, 1024))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = self.fc(x)\n",
    "        x = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(32, 100)\n",
    "x = generator()(z)\n",
    "print(x.shape)\n",
    "\n",
    "out = discriminator()(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = logging.getLogger('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prec1 = 0\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parser():\n",
    "    parser = argparse.ArgumentParser(description='RMCOS-SSL')\n",
    "\n",
    "    parser.add_argument('--dataset', default='cifar10'),\n",
    "\n",
    "    parser.add_argument('--train-subdir', type=str, default='train+val')\n",
    "\n",
    "    parser.add_argument('--eval-subdir', type=str, default='test')\n",
    "\n",
    "    parser.add_argument('--labels', default=\"data-local/labels/cifar10/4000_balanced_labels/00.txt\", type=str)\n",
    "\n",
    "    parser.add_argument('--exclude-unlabeled', default=False, action=\"store_true\")\n",
    "\n",
    "    parser.add_argument('--arch', '-a', default='cifar_shakeshake26')\n",
    "\n",
    "    # # 好像没有resnet18\n",
    "    parser.add_argument('--lrG', type=float, default=0.0002)  # # #\n",
    "    parser.add_argument('--lrD', type=float, default=0.0002)  # # #\n",
    "    parser.add_argument('--beta1', type=float, default=0.5)  # # #\n",
    "    parser.add_argument('--beta2', type=float, default=0.999)  # # #\n",
    "\n",
    "    parser.add_argument('--workers', default=4, type=int)\n",
    "\n",
    "    parser.add_argument('--epochs', default=1, type=int)\n",
    "\n",
    "    parser.add_argument('--start-epoch', default=0, type=int)\n",
    "\n",
    "    parser.add_argument('--batch-size', default=128, type=int)\n",
    "\n",
    "    parser.add_argument('--labeled-batch-size', default=64, type=int)\n",
    "\n",
    "    parser.add_argument('--generated-batch-size', type=int, default=128)\n",
    "\n",
    "    parser.add_argument('--z-dim', type=int, default=100)\n",
    "\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float)\n",
    "\n",
    "    parser.add_argument('--initial-lr', default=0.0, type=float)\n",
    "\n",
    "    parser.add_argument('--lr-rampup', default=0, type=int)\n",
    "\n",
    "    parser.add_argument('--lr-rampdown-epochs', default=None, type=int)\n",
    "\n",
    "    parser.add_argument('--momentum', default=0.9, type=float)\n",
    "\n",
    "    parser.add_argument('--nesterov', default=True, action=\"store_true\")\n",
    "\n",
    "    parser.add_argument('--weight-decay', default=1e-4, type=float)\n",
    "\n",
    "    parser.add_argument('--ema-decay', default=0.999, type=float)\n",
    "\n",
    "    parser.add_argument('--consistency', default=100.0, type=float)\n",
    "\n",
    "    parser.add_argument('--consistency-type', default=\"mse\", type=str)\n",
    "\n",
    "    parser.add_argument('--consistency-rampup', default=5, type=int)\n",
    "\n",
    "    parser.add_argument('--logit-distance-cost', default=0.01, type=float)\n",
    "\n",
    "    parser.add_argument('--checkpoint-epochs', default=1, type=int)\n",
    "    parser.add_argument('--evaluation-epochs', default=1, type=int)\n",
    "\n",
    "    parser.add_argument('--print-freq', default=10, type=int)\n",
    "\n",
    "    parser.add_argument('--resume', default='', type=str)\n",
    "\n",
    "    parser.add_argument('--evaluate', default=False, action=\"store_true\")\n",
    "\n",
    "    parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                        help='use pre-trained model')\n",
    "    return parser\n",
    "\n",
    "args = create_parser().parse_args(args=[]) # for jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"out\"\n",
    "date_time_now = datetime.now()\n",
    "\n",
    "checkpoint_path = \"{}/{:%Y-%m-%d_%H:%M:%S}\".format(out_dir, date_time_now)\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "print(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomTranslateWithReflect:\n",
    "    \"\"\"Translate image randomly\n",
    "\n",
    "    Translate vertically and horizontally by n pixels where\n",
    "    n is integer drawn uniformly independently for each axis\n",
    "    from [-max_translation, max_translation].\n",
    "\n",
    "    Fill the uncovered blank area with reflect padding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_translation):\n",
    "        self.max_translation = max_translation\n",
    "\n",
    "    def __call__(self, old_image):\n",
    "        xtranslation, ytranslation = np.random.randint(-self.max_translation,\n",
    "                                                       self.max_translation + 1,\n",
    "                                                       size=2)\n",
    "        xpad, ypad = abs(xtranslation), abs(ytranslation)\n",
    "        xsize, ysize = old_image.size\n",
    "\n",
    "        flipped_lr = old_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        flipped_tb = old_image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        flipped_both = old_image.transpose(Image.ROTATE_180)\n",
    "\n",
    "        new_image = Image.new(\"RGB\", (xsize + 2 * xpad, ysize + 2 * ypad))\n",
    "\n",
    "        new_image.paste(old_image, (xpad, ypad))\n",
    "\n",
    "        new_image.paste(flipped_lr, (xpad + xsize - 1, ypad))\n",
    "        new_image.paste(flipped_lr, (xpad - xsize + 1, ypad))\n",
    "\n",
    "        new_image.paste(flipped_tb, (xpad, ypad + ysize - 1))\n",
    "        new_image.paste(flipped_tb, (xpad, ypad - ysize + 1))\n",
    "\n",
    "        new_image.paste(flipped_both, (xpad - xsize + 1, ypad - ysize + 1))\n",
    "        new_image.paste(flipped_both, (xpad + xsize - 1, ypad - ysize + 1))\n",
    "        new_image.paste(flipped_both, (xpad - xsize + 1, ypad + ysize - 1))\n",
    "        new_image.paste(flipped_both, (xpad + xsize - 1, ypad + ysize - 1))\n",
    "\n",
    "        new_image = new_image.crop((xpad - xtranslation,\n",
    "                                    ypad - ytranslation,\n",
    "                                    xpad + xsize - xtranslation,\n",
    "                                    ypad + ysize - ytranslation))\n",
    "\n",
    "        return new_image\n",
    "\n",
    "\n",
    "class TransformTwice:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        out1 = self.transform(inp)\n",
    "        out2 = self.transform(inp)\n",
    "        return out1, out2\n",
    "\n",
    "\n",
    "def relabel_dataset(dataset, labels):\n",
    "    unlabeled_idxs = []\n",
    "    for idx in range(len(dataset.imgs)):\n",
    "        path, _ = dataset.imgs[idx]  # # dataset.imgs里面存的是(path,label)\n",
    "        filename = os.path.basename(path)\n",
    "        if filename in labels:\n",
    "            label_idx = dataset.class_to_idx[labels[filename]]  # # class_to_idx存的是{'cat': 0, 'dog': 1}\n",
    "            dataset.imgs[idx] = path, label_idx  # # 重新更新一遍\n",
    "            del labels[filename]\n",
    "        else:\n",
    "            dataset.imgs[idx] = path, NO_LABEL\n",
    "            unlabeled_idxs.append(idx)\n",
    "\n",
    "    if len(labels) != 0:\n",
    "        message = \"List of unlabeled contains {} unknown files: {}, ...\"\n",
    "        some_missing = ', '.join(list(labels.keys())[:5])  # # 为什么有个[:5]\n",
    "        raise LookupError(message.format(len(labels), some_missing))\n",
    "\n",
    "    labeled_idxs = sorted(set(range(len(dataset.imgs))) - set(unlabeled_idxs))\n",
    "\n",
    "    print(\"num of labeled: \" + str(len(labeled_idxs)) + '\\n')\n",
    "    print(\"num of unlabeled: \" + str(len(unlabeled_idxs)) + '\\n')\n",
    "    return labeled_idxs, unlabeled_idxs\n",
    "\n",
    "\n",
    "class TwoStreamBatchSampler(Sampler):\n",
    "    \"\"\"Iterate two sets of indices\n",
    "\n",
    "    An 'epoch' is one iteration through the primary indices.\n",
    "    During the epoch, the secondary indices are iterated through\n",
    "    as many times as needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
    "        self.primary_indices = primary_indices\n",
    "        self.secondary_indices = secondary_indices\n",
    "        self.secondary_batch_size = secondary_batch_size\n",
    "        self.primary_batch_size = batch_size - secondary_batch_size\n",
    "\n",
    "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
    "        assert len(self.secondary_indices) >= self.secondary_batch_size > 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        primary_iter = iterate_once(self.primary_indices)\n",
    "        secondary_iter = iterate_eternally(self.secondary_indices)\n",
    "        return (\n",
    "            primary_batch + secondary_batch\n",
    "            for (primary_batch, secondary_batch)\n",
    "            in  zip(grouper(primary_iter, self.primary_batch_size),\n",
    "                    grouper(secondary_iter, self.secondary_batch_size))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.primary_indices) // self.primary_batch_size\n",
    "\n",
    "\n",
    "def iterate_once(iterable):\n",
    "    return np.random.permutation(iterable)\n",
    "\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "\n",
    "def grouper(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3) --> ABC DEF\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def cifar10():\n",
    "\n",
    "    train_transformation = TransformTwice(transforms.Compose([  # # 为什么弄个twice\n",
    "        data.RandomTranslateWithReflect(4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ]))\n",
    "\n",
    "    eval_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        'train_transformation': train_transformation,\n",
    "        'eval_transformation': eval_transformation,\n",
    "        'datadir': 'data-local/images/cifar/cifar10/by-image',\n",
    "        'num_classes': 10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = datasets.__dict__[args.dataset]()\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = dataset_config.pop('num_classes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [args.exclude_unlabeled, args.labeled_batch_size]\n",
    "print(lst)\n",
    "print(sum(int(bool(el)) for el in lst) == 1, \", \".join(str(el) for el in lst))\n",
    "assert_exactly_one([args.exclude_unlabeled, args.labeled_batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_exactly_one(lst):\n",
    "    assert sum(int(bool(el)) for el in lst) == 1, \", \".join(str(el) for el in lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = dataset_config[\"train_transformation\"]\n",
    "datadir = dataset_config[\"datadir\"]\n",
    "traindir = os.path.join(datadir, args.train_subdir)\n",
    "evaldir = os.path.join(datadir, args.eval_subdir)\n",
    "\n",
    "print(train_transformation)\n",
    "print(traindir)\n",
    "print(evaldir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(traindir, train_transformation)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(traindir, train_transformation)\n",
    "\n",
    "with open(args.labels) as f:\n",
    "    labels = dict(line.split(' ') for line in f.read().splitlines())\n",
    "\n",
    "labeled_idxs, unlabeled_idxs = relabel_dataset(dataset, labels)\n",
    "len(labeled_idxs), type(labeled_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(train_transformation,\n",
    "                        eval_transformation,\n",
    "                        datadir,\n",
    "                        args):\n",
    "    traindir = os.path.join(datadir, args.train_subdir)\n",
    "    evaldir = os.path.join(datadir, args.eval_subdir)\n",
    "\n",
    "    assert_exactly_one([args.exclude_unlabeled, args.labeled_batch_size])\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder(traindir, train_transformation)\n",
    "\n",
    "    if args.labels:\n",
    "        with open(args.labels) as f:\n",
    "            labels = dict(line.split(' ') for line in f.read().splitlines())\n",
    "        labeled_idxs, unlabeled_idxs = data.relabel_dataset(dataset, labels)\n",
    "\n",
    "    if args.exclude_unlabeled: # False\n",
    "        sampler = SubsetRandomSampler(labeled_idxs)\n",
    "        batch_sampler = BatchSampler(sampler, args.batch_size, drop_last=True)\n",
    "    elif args.labeled_batch_size: ## True\n",
    "        batch_sampler = data.TwoStreamBatchSampler(\n",
    "            unlabeled_idxs, labeled_idxs, args.batch_size, args.labeled_batch_size)\n",
    "            # unlabeled: 97, labeled: 31 -> batch_size: 128 \n",
    "    else:\n",
    "        assert False, \"labeled batch size {}\".format(args.labeled_batch_size)\n",
    "\n",
    "    # tao train loader voi 31 labeled va 97 unlabeled\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_sampler=batch_sampler)\n",
    "\n",
    "    eval_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.ImageFolder(evaldir, eval_transformation),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False)\n",
    "\n",
    "    return train_loader, eval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, eval_loader = create_data_loaders(**dataset_config, args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(net): # # #\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "def save_images(images, size, image_path): # # #\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "def imsave(images, size, path): # # #\n",
    "    image = np.squeeze(merge(images, size))\n",
    "    return imageio.imwrite(path, image)\n",
    "\n",
    "def merge(images, size): # # #\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    if (images.shape[3] in (3,4)):\n",
    "        c = images.shape[3]\n",
    "        img = np.zeros((h * size[0], w * size[1], c))\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]\n",
    "            j = idx // size[1]\n",
    "            img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "        return img\n",
    "    elif images.shape[3]==1:\n",
    "        img = np.zeros((h * size[0], w * size[1]))\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]\n",
    "            j = idx // size[1]\n",
    "            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n",
    "        return img\n",
    "    else:\n",
    "        raise ValueError('in merge(images,size) images parameter ''must have dimensions: HxW or HxWx3 or HxWx4')\n",
    "\n",
    "\n",
    "def parameters_string(module):\n",
    "    lines = [\n",
    "        \"\",\n",
    "        \"List of model parameters:\",\n",
    "        \"=========================\",\n",
    "    ]\n",
    "\n",
    "    row_format = \"{name:<40} {shape:>20} ={total_size:>12,d}\"\n",
    "    params = list(module.named_parameters())\n",
    "    for name, param in params:\n",
    "        lines.append(row_format.format(\n",
    "            name=name,\n",
    "            shape=\" * \".join(str(p) for p in param.size()),\n",
    "            total_size=param.numel()\n",
    "        ))\n",
    "    lines.append(\"=\" * 75)\n",
    "    lines.append(row_format.format(\n",
    "        name=\"all parameters\",\n",
    "        shape=\"sum of above\",\n",
    "        total_size=sum(int(param.numel()) for name, param in params)\n",
    "    ))\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def assert_exactly_one(lst):\n",
    "    assert sum(int(bool(el)) for el in lst) == 1, \", \".join(str(el) for el in lst)\n",
    "\n",
    "\n",
    "class AverageMeterSet:\n",
    "    def __init__(self):\n",
    "        self.meters = {}\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.meters[key]\n",
    "\n",
    "    def update(self, name, value, n=1):\n",
    "        if not name in self.meters:\n",
    "            self.meters[name] = AverageMeter()\n",
    "        self.meters[name].update(value, n)\n",
    "\n",
    "    def reset(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "    def values(self, postfix=''):\n",
    "        return {name + postfix: meter.val for name, meter in self.meters.items()}\n",
    "\n",
    "    def averages(self, postfix='/avg'):\n",
    "        return {name + postfix: meter.avg for name, meter in self.meters.items()}\n",
    "\n",
    "    def sums(self, postfix='/sum'):\n",
    "        return {name + postfix: meter.sum for name, meter in self.meters.items()}\n",
    "\n",
    "    def counts(self, postfix='/count'):\n",
    "        return {name + postfix: meter.count for name, meter in self.meters.items()}\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __format__(self, format):\n",
    "        return \"{self.val:{format}} ({self.avg:{format}})\".format(self=self, format=format)\n",
    "\n",
    "\n",
    "def export(fn):\n",
    "    mod = sys.modules[fn.__module__]\n",
    "    if hasattr(mod, '__all__'):  # 检查是否具有某个属性\n",
    "        mod.__all__.append(fn.__name__)\n",
    "    else:\n",
    "        mod.__all__ = [fn.__name__]\n",
    "    return fn\n",
    "\n",
    "\n",
    "def parameter_count(module):\n",
    "    return sum(int(param.numel()) for param in module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures.__dict__[args.arch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = False\n",
    "LOG.info(\"=> creating {pretrained}{ema}model '{arch}'\".format(\n",
    "pretrained='pre-trained ' if args.pretrained else '',\n",
    "ema='EMA ' if ema else '',\n",
    "arch=args.arch))\n",
    "\n",
    "model_factory = architectures.__dict__[args.arch]\n",
    "model_params = dict(pretrained=args.pretrained, num_classes=num_classes)\n",
    "model = model_factory(**model_params)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(ema=False):\n",
    "        LOG.info(\"=> creating {pretrained}{ema}model '{arch}'\".format(\n",
    "            pretrained='pre-trained ' if args.pretrained else '',\n",
    "            ema='EMA ' if ema else '',\n",
    "            arch=args.arch))\n",
    "\n",
    "        model_factory = architectures.__dict__[args.arch]\n",
    "        model_params = dict(pretrained=args.pretrained, num_classes=num_classes)\n",
    "        model = model_factory(**model_params)\n",
    "\n",
    "        if ema:  # # exponential moving average\n",
    "            for param in model.parameters():\n",
    "                param.detach_()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "ema_model = create_model(ema=True)\n",
    "\n",
    "model.cuda()\n",
    "ema_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(input_dim=args.z_dim, output_dim=3, input_size=32)\n",
    "D = discriminator(input_dim=3, output_dim=1, input_size=32)\n",
    "G.cuda()\n",
    "D.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay,\n",
    "                            nesterov=args.nesterov)\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
    "\n",
    "# loss\n",
    "\n",
    "BCEloss = nn.BCEWithLogitsLoss().cuda()\n",
    "\n",
    "def nll_loss_neg(y_pred, y_true):  # # #\n",
    "    out = torch.sum(y_true * y_pred, dim=1)\n",
    "    return torch.mean(- torch.log((1 - out) + 1e-6))\n",
    "\n",
    "def inverted_cross_entropy(y_pred, y_true):\n",
    "    out = - torch.mean(y_true * torch.log(1-y_pred + 1e-6) + 1e-6)\n",
    "    return out\n",
    "\n",
    "# bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def d_loss(real, fake, y, m=0.15, s=10.0):\n",
    "    real = real - m\n",
    "    return BCEloss(s*(real - fake) + 1e-6 , y)\n",
    "\n",
    "def g_loss(real, fake, y, m=0.15, s=10.0):\n",
    "    fake = fake + m\n",
    "    return BCEloss(s*(fake - real) + 1e-6, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "        LOG.info(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        # exit()\n",
    "\n",
    "        best_file = os.path.join(args.resume, 'best.ckpt')\n",
    "        G_file = os.path.join(args.resume, 'G.pkl')\n",
    "        C_file = os.path.join(args.resume, 'D.pkl')\n",
    "\n",
    "        assert os.path.isfile(best_file), \"=> no checkpoint found at '{}'\".format(best_file)\n",
    "        assert os.path.isfile(G_file), \"=> no checkpoint found at '{}'\".format(G_file)\n",
    "        assert os.path.isfile(C_file), \"=> no checkpoint found at '{}'\".format(C_file)\n",
    "\n",
    "        checkpoint = torch.load(best_file)\n",
    "        # print(checkpoint.keys())\n",
    "        # exit()\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        global_step = checkpoint['global_step']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        ema_model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        G.load_state_dict(torch.load(G_file))\n",
    "        D.load_state_dict(torch.load(C_file))\n",
    "\n",
    "        print('----------------best_precl----------------', best_prec1)\n",
    "\n",
    "        LOG.info(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark =  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(eval_loader, model, log, global_step, epoch):\n",
    "    if torch.cuda.is_available():\n",
    "        class_criterion = nn.CrossEntropyLoss(size_average=False, ignore_index=NO_LABEL).cuda()\n",
    "    else:\n",
    "        class_criterion = nn.CrossEntropyLoss(size_average=False, ignore_index=NO_LABEL)\n",
    "\n",
    "    meters = AverageMeterSet()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(eval_loader):\n",
    "        meters.update('data_time', time.time() - end)\n",
    "        if torch.cuda.is_available():\n",
    "            input_var = torch.autograd.Variable(input.cuda(), volatile=True)\n",
    "            target_var = torch.autograd.Variable(target.cuda(), volatile=True)\n",
    "        else:          \n",
    "            input_var = torch.autograd.Variable(input, volatile=True)\n",
    "            target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        minibatch_size = len(target_var)\n",
    "        labeled_minibatch_size = target_var.data.ne(NO_LABEL).sum()\n",
    "        assert labeled_minibatch_size > 0\n",
    "        meters.update('labeled_minibatch_size', labeled_minibatch_size)\n",
    "\n",
    "        # compute output\n",
    "        output1, output2 = model(input_var)\n",
    "        softmax1, softmax2 = F.softmax(output1, dim=1), F.softmax(output2, dim=1)\n",
    "        class_loss = class_criterion(output1, target_var) / minibatch_size\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output1.data, target_var.data, topk=(1, 5))\n",
    "        meters.update('class_loss', class_loss.item(), labeled_minibatch_size)\n",
    "        meters.update('top1', prec1[0], labeled_minibatch_size)\n",
    "        meters.update('error1', 100.0 - prec1[0], labeled_minibatch_size)\n",
    "        meters.update('top5', prec5[0], labeled_minibatch_size)\n",
    "        meters.update('error5', 100.0 - prec5[0], labeled_minibatch_size)\n",
    "\n",
    "        # measure elapsed time\n",
    "        meters.update('batch_time', time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            LOG.info(\n",
    "                'Test: [{0}/{1}]\\t'\n",
    "                'Time {meters[batch_time]:.3f}\\t'\n",
    "                'Data {meters[data_time]:.3f}\\t'\n",
    "                'Class {meters[class_loss]:.4f}\\t'\n",
    "                'Prec@1 {meters[top1]:.3f}\\t'\n",
    "                'Prec@5 {meters[top5]:.3f}'.format(\n",
    "                    i, len(eval_loader), meters=meters))\n",
    "\n",
    "    LOG.info(' * Prec@1 {top1.avg:.3f}\\tPrec@5 {top5.avg:.3f}'\n",
    "          .format(top1=meters['top1'], top5=meters['top5']))\n",
    "\n",
    "\n",
    "    return meters['top1'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, dirpath, epoch):\n",
    "    best_path = os.path.join(dirpath, 'best.ckpt')\n",
    "    torch.save(state, best_path)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, step_in_epoch, total_steps_in_epoch):\n",
    "    lr = args.lr\n",
    "    epoch = epoch + step_in_epoch / total_steps_in_epoch\n",
    "\n",
    "    # LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677\n",
    "    lr = ramps.linear_rampup(epoch, args.lr_rampup) * (args.lr - args.initial_lr) + args.initial_lr\n",
    "\n",
    "    # Cosine LR rampdown from https://arxiv.org/abs/1608.03983 (but one cycle only)\n",
    "    if args.lr_rampdown_epochs:\n",
    "        assert args.lr_rampdown_epochs >= args.epochs\n",
    "        lr *= ramps.cosine_rampdown(epoch, args.lr_rampdown_epochs)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def get_current_consistency_weight(epoch):\n",
    "    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "    return args.consistency * ramps.sigmoid_rampup(epoch, args.consistency_rampup)\n",
    "\n",
    "def generated_weight(epoch):\n",
    "    alpha = 0.0\n",
    "    T1 = 10\n",
    "    T2 = 60\n",
    "    af = 0.3\n",
    "    if epoch > T1:\n",
    "        alpha = (epoch-T1) / (T2-T1)*af\n",
    "        if epoch > T2:\n",
    "            alpha = af\n",
    "    return alpha\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    labeled_minibatch_size = max(target.ne(NO_LABEL).sum(), 1e-8)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / labeled_minibatch_size.float()))\n",
    "    return res\n",
    "    \n",
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "def visualize_results(G, epoch):\n",
    "    G.eval()\n",
    "    generated_images_dir = 'generated_images/' + args.dataset\n",
    "    if not os.path.exists(generated_images_dir):\n",
    "        os.makedirs(generated_images_dir)\n",
    "\n",
    "    tot_num_samples = 64\n",
    "    image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "\n",
    "    sample_z_ = torch.rand((tot_num_samples, args.z_dim))\n",
    "\n",
    "    sample_z_ = sample_z_.cuda()\n",
    "\n",
    "    samples = G(sample_z_)\n",
    "\n",
    "\n",
    "    samples = samples.mul(0.5).add(0.5)\n",
    "\n",
    "    samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "    save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                      generated_images_dir + '/' + 'epoch%03d' % epoch + '.png')\n",
    "                          \n",
    "def train(train_loader, model, ema_model, optimizer, G, D, G_optimizer, D_optimizer, epoch, log, BCEloss):\n",
    "    global global_step\n",
    "\n",
    "    class_criterion = nn.CrossEntropyLoss(size_average=False, ignore_index=NO_LABEL).cuda()\n",
    "    if args.consistency_type == 'mse':\n",
    "        consistency_criterion = losses.softmax_mse_loss\n",
    "    elif args.consistency_type == 'kl':\n",
    "        consistency_criterion = losses.softmax_kl_loss\n",
    "    else:\n",
    "        assert False, args.consistency_type\n",
    "    residual_logit_criterion = losses.symmetric_mse_loss\n",
    "\n",
    "    meters = AverageMeterSet()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    ema_model.train()\n",
    "    D.train()\n",
    "    G.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    # y_real = \n",
    "\n",
    "\n",
    "\n",
    "    for i, ((input, ema_input), target) in enumerate(train_loader):\n",
    "        # print(\"input\", input.shape) # (128, 3, 32, 32)\n",
    "        # print(\"ema input\", ema_input.shape) # (128, 3, 32, 32)\n",
    "        # print(\"target\", target.shape) # 128\n",
    "\n",
    "        # measure data loading time\n",
    "        meters.update('data_time', time.time() - end)\n",
    "        # print(meters['data_time'])\n",
    "\n",
    "        adjust_learning_rate(optimizer, epoch, i, len(train_loader))\n",
    "        meters.update('lr', optimizer.param_groups[0]['lr'])\n",
    "        # print(meters[\"lr\"])\n",
    "\n",
    "        input_var = torch.autograd.Variable(input.cuda())\n",
    "        ema_input_var = torch.autograd.Variable(ema_input.cuda(), volatile=True)\n",
    "        target_var = torch.autograd.Variable(target.cuda())\n",
    "\n",
    "        minibatch_size = len(target_var)\n",
    "        labeled_minibatch_size = target_var.data.ne(NO_LABEL).sum()\n",
    "        # print(\"labeled batchsize\", labeled_minibatch_size) # 31\n",
    "        assert labeled_minibatch_size > 0\n",
    "        meters.update('labeled_minibatch_size', labeled_minibatch_size)\n",
    "\n",
    "        ema_model_out = ema_model(ema_input_var) # tuple shape (128, 10), (128, 10 )\n",
    "        model_out = model(input_var) # nhu tren\n",
    "\n",
    "        if isinstance(model_out, Variable): # False\n",
    "            assert args.logit_distance_cost < 0\n",
    "            logit1 = model_out\n",
    "            ema_logit = ema_model_out\n",
    "        else:  \n",
    "            assert len(model_out) == 2\n",
    "            assert len(ema_model_out) == 2\n",
    "            logit1, logit2 = model_out\n",
    "            ema_logit, _ = ema_model_out\n",
    "\n",
    "        ema_logit = Variable(ema_logit.detach().data, requires_grad=False)\n",
    "\n",
    "        if args.logit_distance_cost >= 0: # 0.01\n",
    "            class_logit, cons_logit = logit1, logit2\n",
    "            res_loss = args.logit_distance_cost * residual_logit_criterion(class_logit, cons_logit) / minibatch_size\n",
    "            meters.update('res_loss', res_loss.item())\n",
    "\n",
    "        else:\n",
    "            class_logit, cons_logit = logit1, logit1\n",
    "            res_loss = 0\n",
    "\n",
    "        class_loss = class_criterion(class_logit, target_var) / minibatch_size\n",
    "        meters.update('class_loss', class_loss.item())\n",
    "\n",
    "        ema_class_loss = class_criterion(ema_logit, target_var) / minibatch_size\n",
    "        meters.update('ema_class_loss', ema_class_loss.item())\n",
    "\n",
    "        if args.consistency: # 100\n",
    "            consistency_weight = get_current_consistency_weight(epoch)\n",
    "            meters.update('cons_weight', consistency_weight)\n",
    "            consistency_loss = consistency_weight * consistency_criterion(cons_logit, ema_logit) / minibatch_size\n",
    "\n",
    "\n",
    "            meters.update('cons_loss', consistency_loss.item())\n",
    "        else:\n",
    "            consistency_loss = 0\n",
    "            meters.update('cons_loss', 0)\n",
    "\n",
    "\n",
    "        z_ = torch.rand((args.generated_batch_size, args.z_dim))\n",
    "        z_ = z_.cuda()\n",
    "        G_ = G(z_)\n",
    "\n",
    "        C_fake_pred, _ = model(G_)\n",
    "\n",
    "        C_fake_pred = F.softmax(C_fake_pred, dim=1)\n",
    "        with torch.no_grad():\n",
    "            C_fake_wei = torch.max(C_fake_pred, 1)[1]\n",
    "            C_fake_wei = C_fake_wei.view(-1, 1)\n",
    "            C_fake_wei = torch.zeros(args.generated_batch_size, 10).cuda().scatter_(1, C_fake_wei, 1)\n",
    "\n",
    "        # C_fake_loss = nll_loss_neg(C_fake_pred, C_fake_wei)\n",
    "        C_fake_loss = inverted_cross_entropy(C_fake_pred, C_fake_wei)\n",
    "\n",
    "        loss = class_loss + consistency_loss + res_loss + generated_weight(epoch) * C_fake_loss\n",
    "\n",
    "        assert not (np.isnan(loss.item()) or loss.item() > 1e5), 'Loss explosion: {}'.format(loss.item())\n",
    "        meters.update('loss', loss.item())\n",
    "\n",
    "        prec1, prec5 = accuracy(class_logit.data, target_var.data, topk=(1, 5))\n",
    "        meters.update('top1', prec1[0], labeled_minibatch_size)\n",
    "        meters.update('error1', 100. - prec1[0], labeled_minibatch_size)\n",
    "        meters.update('top5', prec5[0], labeled_minibatch_size)\n",
    "        meters.update('error5', 100. - prec5[0], labeled_minibatch_size)\n",
    "\n",
    "        ema_prec1, ema_prec5 = accuracy(ema_logit.data, target_var.data, topk=(1, 5))\n",
    "        meters.update('ema_top1', ema_prec1[0], labeled_minibatch_size)\n",
    "        meters.update('ema_error1', 100. - ema_prec1[0], labeled_minibatch_size)\n",
    "        meters.update('ema_top5', ema_prec5[0], labeled_minibatch_size)\n",
    "        meters.update('ema_error5', 100. - ema_prec5[0], labeled_minibatch_size)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        update_ema_variables(model, ema_model, args.ema_decay, global_step)\n",
    "\n",
    "        # measure elapsed time\n",
    "        meters.update('batch_time', time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            LOG.info(\n",
    "                'Epoch: [{0}][{1}/{2}]\\t'\n",
    "                'Time {meters[batch_time]:.3f}\\t'\n",
    "                'Data {meters[data_time]:.3f}\\t'\n",
    "                'Class {meters[class_loss]:.4f}\\t'\n",
    "                'Cons {meters[cons_loss]:.4f}\\t'\n",
    "                'Prec@1 {meters[top1]:.3f}\\t'\n",
    "                'Prec@5 {meters[top5]:.3f}'.format(\n",
    "                    epoch, i, len(train_loader), meters=meters))\n",
    "\n",
    "\n",
    "        # update D network\n",
    "        D_optimizer.zero_grad()\n",
    "\n",
    "        # sửa hai hàm loss chỗ này !!! \n",
    "        # input_var là gì ? \n",
    "\n",
    "        D_real = D(input_var) # (128, 1)\n",
    "        # D_real_loss = BCEloss(D_real, torch.ones_like(D_real)) # scalar\n",
    "\n",
    "        G_ = G(z_)\n",
    "        D_fake = D(G_) # (32, 1)\n",
    "\n",
    "        # D_fake_loss = BCEloss(D_fake, torch.zeros_like(D_fake)) # scalar\n",
    "\n",
    "        # D_loss = D_real_loss + D_fake_loss # scalar + scalar\n",
    "        D_loss = d_loss(D_real, D_fake, torch.ones_like(D_real))\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # update G network\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        G_ = G(z_)\n",
    "\n",
    "        D_real = D(input_var)\n",
    "        D_fake = D(G_)\n",
    "        # G_loss_D = BCEloss(D_fake, torch.ones_like(D_fake))\n",
    "        G_loss_D = g_loss(D_real, D_fake, torch.ones_like(D_fake))\n",
    "\n",
    "        C_fake_pred, _ = model(G_)\n",
    "        C_fake_pred = F.log_softmax(C_fake_pred, dim=1)\n",
    "        with torch.no_grad():\n",
    "            C_fake_wei = torch.max(C_fake_pred, 1)[1]\n",
    "        G_loss_C = F.nll_loss(C_fake_pred, C_fake_wei)\n",
    "\n",
    "        G_loss = G_loss_D + generated_weight(epoch) * G_loss_C\n",
    "        if epoch <= 10:\n",
    "            G_loss_D.backward()\n",
    "        else:\n",
    "            G_loss_D.backward(retain_graph=True)\n",
    "            G_loss_C.backward()\n",
    "\n",
    "        G_optimizer.step()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                  (\n",
    "                      epoch, i, len(train_loader),\n",
    "                      D_loss.item(),\n",
    "                      G_loss.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        visualize_results(G, (epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "        start_time = time.time()\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, ema_model, optimizer, G, D, G_optimizer, D_optimizer, epoch, training_log, BCEloss)\n",
    "        LOG.info(\"--- training epoch in %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        if args.evaluation_epochs and (epoch + 1) % args.evaluation_epochs == 0:\n",
    "            start_time = time.time()\n",
    "            LOG.info(\"Evaluating the primary model:\")\n",
    "            prec1 = validate(eval_loader, model, validation_log, global_step, epoch + 1)\n",
    "            LOG.info(\"Evaluating the EMA model:\")\n",
    "            ema_prec1 = validate(eval_loader, ema_model, ema_validation_log, global_step, epoch + 1)\n",
    "            LOG.info(\"--- validation in %s seconds ---\" % (time.time() - start_time))\n",
    "            is_best = ema_prec1 > best_prec1\n",
    "            best_prec1 = max(ema_prec1, best_prec1)\n",
    "        else:\n",
    "            is_best = False\n",
    "\n",
    "        if args.checkpoint_epochs and (epoch + 1) % args.checkpoint_epochs == 0 and is_best:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'global_step': global_step,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'ema_state_dict': ema_model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, is_best, checkpoint_path, epoch + 1)\n",
    "            torch.save(G.state_dict(), os.path.join(checkpoint_path, 'G.pkl'))\n",
    "            torch.save(D.state_dict(), os.path.join(checkpoint_path, 'D.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97a9b6343f65fe012e586d2341faeec3de1aac542abc926e13e5cd9da3a81b0a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('my_crawler')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
